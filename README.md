# Plot-Political-Compass

This repository contains Python scripts for scraping political ideology data, assigning extremism ratings and compass coordinates using the Gemini API, fine-tuning a DistilBERT model, and visualizing user input on a political compass.

### Repository Structure and File Descriptions

  * **`data.py`**: Scrapes political ideology data from `polcompball.wikitide.org`. Extracts article body text and infobox details for each ideology.

      * **Output**: `political_ideologies_structured_data.jsonl` (raw scraped data).

  * **`rating.py`**: Assigns an "extremism rating" (0-100%) to each ideology. Uses the Gemini API for rating, leveraging predefined ratings and contextual information from related ideologies in a graph structure.

      * **Input**: `political_ideologies_structured_data.jsonl`, `ideology_influence_graph.json` (graph of ideology influences).
      * **Output**: `tierlistgraph.json` (ideologies with extremism ratings), `tier1_ideologies.json`, `tier2_ideologies.json`, `tier3_ideologies.json`, `tier4_ideologies.json` (tiered ideology data based on extremism).

  * **`coordinates.py`**: Assigns political compass (X, Y) coordinates to each ideology. Uses the Gemini API, considering ideology descriptions, alignments, extremism ratings, and coordinates of related ideologies.

      * **Input**: `political_ideologies_structured_data.jsonl`, `ideology_influence_graph.json`, `tierlistgraph.json`, `tier[1-4]_ideologies.json`.
      * **Output**: `political_ideologies_coordinates.jsonl` (ideologies with assigned coordinates).
      * **Temporary File**: `temp_tier_order.json` (deleted after use).

  * **`train_dilstilbert.py`**: Fine-tunes a DistilBERT model for regression. Trains the model to predict (X, Y) coordinates based on ideology text descriptions. Includes checkpointing for resuming training.

      * **Input**: `political_ideologies_coordinates.jsonl`.
      * **Output**: `distilbert_checkpoints/final_model/` (contains the fine-tuned DistilBERT model and tokenizer).

  * **`plot.py`**: Takes user-provided text input, uses the fine-tuned DistilBERT model to predict its political compass coordinates, and generates an interactive HTML visualization.

      * **Input**: `political_ideologies_coordinates.jsonl`, `distilbert_checkpoints/final_model/`.
      * **Output**: `user_compass_prediction.html` (interactive visualization).

  * **`requirements.txt`**: Lists all Python packages required for the project.

  * **`political_ideologies_structured_data.jsonl`**: Contains scraped ideology names, article bodies, and infobox details. Generated by `data.py`.

  * **`ideology_influence_graph.json`**: Represents the influence relationships between ideologies. (Generated by a prior, unlisted program, but is a dependency for `rating.py` and `program6_coordinate_rater.py`).

  * **`tierlistgraph.json`**: Stores ideologies with their assigned extremism ratings. Generated by `rating.py`.

  * **`tier[1-4]_ideologies.json`**: Individual JSON files for ideologies categorized by extremism tier. Generated by `rating.py`.

  * **`political_ideologies_coordinates.jsonl`**: Final dataset of ideologies with their assigned political compass coordinates. Generated by `coordinates.py`.

  * **`ideology_names.json`**: Just a file with all ideologies listed. Thats it.

  * **`political_ideologies_predictions_and_interpretations.jsonl`**: (An older output file from a previous iteration. Not directly used by the current `plot.py`).

### Missing Files (Not Included in Repository)

Due to file size limitations, the actual fine-tuned DistilBERT model and tokenizer are not included:

  * `distilbert_checkpoints/` (This directory, containing `final_model/` and `checkpoint-*` folders, is generated by `train_dilstilbert.py`).

### Training `train_dilstilbert.py`

`train_dilstilbert.py` was primarily developed and run in a Google Colab environment. This was due to:

  * **GPU Access**: Fine-tuning large language models like DistilBERT is computationally intensive and requires a GPU. Colab provides free access to GPUs.
  * **Resource Constraints**: Local machines (especially consumer-grade) often lack sufficient VRAM for efficient transformer model training.

### Running in Google Colab

To run this project in Google Colab:

1.  **Upload files**: Upload all `.py` and `.jsonl`/`.json` files (except `distilbert_checkpoints/`) to a Google Drive folder (e.g., `PoliticalCompassData`).
2.  **Mount Google Drive**: In your Colab notebook, mount your Google Drive:
    ```python
    from google.colab import drive
    drive.mount('/content/drive')
    ```
3.  **Adjust `base_path`**: Modify the `base_path` variable in each script to point to your Google Drive folder (e.g., `base_path = "/content/drive/MyDrive/PoliticalCompassData/"`).
4.  **Install dependencies**: Run `!pip install -r requirements.txt` in a Colab cell.
5.  **Execute scripts**: Run each program sequentially (e.g., `!data.py`). For `rating.py` and `coordinates.py`, you may need to re-run the cell multiple times if API quotas are hit. `train_dilstilbert.py` will also benefit from checkpointing for longer training sessions.


### Install Requirements:
   ```python
   pip install -r requirements.txt
   ```
